/* Master TODO list for CS3141 Team A */
/* Not comprehensive, will be updated periodically */

In C:

Get "shell" input working
    1 Print shell lines
    2 Wait for user to type in command and hit enter
    3 Echo back the output and return to step 1

Get System Calls and Non-Blocking IO Setup

Get "help" text/tutorial system working:
    There should be standardized help instructions for shell and specific command usage 

Generate initialization module
    On first startup of tool users should be prompted for config data.
    What this is and how we handle it is TBD. 

Figure out how to handle state based flow:
    I.e. when there is a process executing, handle whether or not it needs to block 
    I/O to the rest of the shell.

    How do we handle timeouts to ensure our shell doesn't hang?
    How do we save the shell state of a most recent session?
    What do we do with data collected by modules when a session is terminated mid-run?

Set up testing infrastructure:
    Begin tracking stack/heap usage once the program begins running to monitor system resources
    Write a master suite of unit tests which: 
        Test relevant combinations of modules
        Run test suites attached to each individual python module
        fork/exec/return in different ways along with
        Run these tests each time new code is pushed to github to ensure it doesn't break our tool

---------------------------------------------------------------------------------------

In Python:

Figure out data storage:

    We will be tracking a lot of different data points/types over time, so we need a storage format that will make it
    easy to parse/access.

    I think JSON would be the easiest format for the data. Python has JSON parsing libraries we could use. For
    example, if we're tracking academic work hours we'd want to track hours worked, subject studied, and progress towards
    goal. In JSON a single entry would be formatted as something like:

    {
        "hoursWorked" : 3,
        "subject"     : "TSP",
        "progress"    : "Sufficient"
    }

    There may be a better way to represent that specific example, but the main idea is that one data entry point will
    contain several different fields. If we have hundreds of entries like the one above, JSON will make it easy to parse.

    Any python module that outputs trackable data will need to adhere to this standard, so it may be easiest to have on
    team member work on JSON I/O specifically.
    
    TODO:
    1 Figure out how to export python data in JSON format (outputting to a .txt or .json file is fine)
    2 Figure out how to import that JSON data into a python program
    
    For these you can use the example given above or come up with something else. It would be a good idea to make a loop
    that generates hundreds of entries for testing purposes.


Data Visualizations (Charts, Graphs, etc):
    
    We need a way to display our beautifully stored data graphically. Python has a lot of options in this regard
    starting with matplotlib. The matplotlib library is easy enough to use and can make simple graphs. Off the top of my
    head this is the only library I'm familiar with so this one is pretty open ended.

    In the end we want real easy to read and good looking graphs, so this would be a good task for someone to dedicate
    themselves to.

    TODO:
    1 Make some dummy data (or grab JSON data if we have it)
    2 Play around with plotting the data in different ways (line chart, bar graph, etc.)
    3 Figure out how to "beautify" simple graphs 


// Gotta think about this section a lot more
Modules:

    Individual python files will be used to implement command line commands. These haven't been nailed down, so for now
    we should begin to implement core functionality for time management, activity selection, and random project
    selection.

    TODO:
    1 Generate a list of projects and randomly select one to be given as output
    2 Figure out how to start/stop a timer in python
    3 Figure out how to receive user input in python (I think this is just one builtin command) 


Testing Infrastructure:

    Each module will need to be tested for individual functionality against edge cases (idk what those will look like)
    Each module will need an automated test suite attached to it which will be run as part of a master test suite
    (Flex but would be cool) Everytime new code is pushed to github it must run against these tests


Object Oriented Design:

    Python can effectively implement object oriented designs which I believe is the best way to handle our data's
    polymorphism. We will be tracking both system and user defined types of data which will share many baseline
    characteristics such as: 
        - Time Tracking variables
        - Efficiency/Performance Tracking Variables
        - Initialization Data
        - Storage Methods
        - General Structure
        - etc etc

    In order to support this a few general data templates will be offered to the user. These can all stem from a generic
    "Data_Entry" class and be related to one another.

    I haven't done any OOP since Data Structures a few years back, so I can't get much more specific than this.
   
    TODO:
    **One big chunk of work will be designing this system (UML/Class diagram?) and implementing it in Python

 -------------------------------------------------------------------------------------------------------
This list is far from comprehensive, so feel free to add stuff as you go. There is also research to be done in
optimizing/finding the most efficient way to accomplish these goals. 

=============================
Considerations Moving Forward
=============================

Is there a more efficient way to structure our code to make it modular than OOP?
